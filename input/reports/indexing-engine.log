10:31:38,638 graphrag.config.read_dotenv INFO Loading pipeline .env file
10:31:38,642 graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 56",
        "type": "openai_chat",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "request_timeout": 180.0,
        "api_base": null,
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": ".",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
10:31:38,644 graphrag.index.create_pipeline_config INFO skipping workflows 
10:31:38,647 graphrag.index.run INFO Running pipeline
10:31:38,647 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at output/20240719-103138/artifacts
10:31:38,647 graphrag.index.input.load_input INFO loading input from root_dir=input
10:31:38,648 graphrag.index.input.load_input INFO using file storage for input
10:31:38,649 graphrag.index.storage.file_pipeline_storage INFO search input for files matching .*\.txt$
10:31:38,650 graphrag.index.input.text INFO found text files from input, found [('tft.txt', {})]
10:31:38,654 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
10:31:38,654 graphrag.index.run INFO Final # of rows loaded: 1
10:31:38,753 graphrag.index.run INFO Running workflow: create_base_text_units...
10:31:38,753 graphrag.index.run INFO dependencies for create_base_text_units: []
10:31:38,758 datashaper.workflow.workflow INFO executing verb orderby
10:31:38,760 datashaper.workflow.workflow INFO executing verb zip
10:31:38,764 datashaper.workflow.workflow INFO executing verb aggregate_override
10:31:38,768 datashaper.workflow.workflow INFO executing verb chunk
10:31:38,930 datashaper.workflow.workflow INFO executing verb select
10:31:38,934 datashaper.workflow.workflow INFO executing verb unroll
10:31:38,939 datashaper.workflow.workflow INFO executing verb rename
10:31:38,946 datashaper.workflow.workflow INFO executing verb genid
10:31:38,954 datashaper.workflow.workflow INFO executing verb unzip
10:31:38,963 datashaper.workflow.workflow INFO executing verb copy
10:31:38,967 datashaper.workflow.workflow INFO executing verb filter
10:31:38,981 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
10:31:39,104 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
10:31:39,104 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
10:31:39,104 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
10:31:39,117 datashaper.workflow.workflow INFO executing verb entity_extract
10:31:39,119 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=None
10:31:39,148 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4o-mini: TPM=0, RPM=0
10:31:39,148 graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4o-mini: 25
10:31:42,797 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:31:42,801 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.6419999999998254. input_tokens=2234, output_tokens=347
10:31:46,139 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:31:46,143 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.989999999999782. input_tokens=2234, output_tokens=368
10:31:46,722 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:31:46,724 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.551000000000386. input_tokens=2041, output_tokens=615
10:31:47,922 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:31:47,928 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.756999999999607. input_tokens=2234, output_tokens=477
10:31:48,39 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:31:48,40 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.877999999999702. input_tokens=2234, output_tokens=740
10:32:00,271 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:00,283 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 21.110999999999876. input_tokens=2234, output_tokens=1415
10:32:08,677 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:08,909 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.743000000000393. input_tokens=2234, output_tokens=1990
10:32:08,924 datashaper.workflow.workflow INFO executing verb merge_graphs
10:32:08,937 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
10:32:09,56 graphrag.index.run INFO Running workflow: create_summarized_entities...
10:32:09,56 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
10:32:09,61 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
10:32:09,74 datashaper.workflow.workflow INFO executing verb summarize_descriptions
10:32:10,80 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,89 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9660000000003492. input_tokens=157, output_tokens=28
10:32:10,379 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,382 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2869999999993524. input_tokens=171, output_tokens=45
10:32:10,395 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,398 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,401 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2770000000000437. input_tokens=160, output_tokens=40
10:32:10,404 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2879999999995562. input_tokens=166, output_tokens=51
10:32:10,421 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,423 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2780000000002474. input_tokens=170, output_tokens=41
10:32:10,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,436 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2929999999996653. input_tokens=168, output_tokens=50
10:32:10,447 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,448 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3220000000001164. input_tokens=161, output_tokens=42
10:32:10,477 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,480 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3809999999994034. input_tokens=165, output_tokens=40
10:32:10,633 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,637 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5169999999998254. input_tokens=163, output_tokens=46
10:32:10,665 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,666 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5390000000006694. input_tokens=175, output_tokens=46
10:32:10,667 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,670 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5300000000006548. input_tokens=172, output_tokens=56
10:32:10,714 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,718 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6040000000002692. input_tokens=162, output_tokens=48
10:32:10,722 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,726 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6199999999998909. input_tokens=185, output_tokens=67
10:32:10,795 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,802 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.670999999999367. input_tokens=161, output_tokens=48
10:32:10,880 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,883 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.75. input_tokens=172, output_tokens=48
10:32:10,890 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,894 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7849999999998545. input_tokens=165, output_tokens=52
10:32:10,990 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,994 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8549999999995634. input_tokens=174, output_tokens=48
10:32:10,996 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:10,999 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.88799999999992. input_tokens=162, output_tokens=41
10:32:11,78 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:11,84 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9369999999998981. input_tokens=174, output_tokens=45
10:32:11,90 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:11,95 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9580000000005384. input_tokens=180, output_tokens=53
10:32:11,142 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:11,147 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.024999999999636. input_tokens=160, output_tokens=39
10:32:11,187 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:11,192 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.087999999999738. input_tokens=188, output_tokens=69
10:32:11,443 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:11,447 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.311999999999898. input_tokens=190, output_tokens=60
10:32:11,449 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:11,453 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.355999999999767. input_tokens=165, output_tokens=87
10:32:11,526 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:11,528 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1149999999997817. input_tokens=181, output_tokens=54
10:32:11,540 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:11,544 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4420000000000073. input_tokens=177, output_tokens=59
10:32:11,736 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:11,741 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3580000000001746. input_tokens=191, output_tokens=49
10:32:11,775 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:11,778 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6880000000001019. input_tokens=194, output_tokens=65
10:32:11,848 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:11,852 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4470000000001164. input_tokens=182, output_tokens=70
10:32:11,876 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
10:32:12,6 graphrag.index.run INFO Running workflow: create_base_entity_graph...
10:32:12,6 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
10:32:12,6 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
10:32:12,19 datashaper.workflow.workflow INFO executing verb cluster_graph
10:32:12,44 datashaper.workflow.workflow INFO executing verb select
10:32:12,46 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
10:32:12,177 graphrag.index.run INFO Running workflow: create_final_entities...
10:32:12,177 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
10:32:12,179 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:32:12,194 datashaper.workflow.workflow INFO executing verb unpack_graph
10:32:12,205 datashaper.workflow.workflow INFO executing verb rename
10:32:12,215 datashaper.workflow.workflow INFO executing verb select
10:32:12,223 datashaper.workflow.workflow INFO executing verb dedupe
10:32:12,231 datashaper.workflow.workflow INFO executing verb rename
10:32:12,239 datashaper.workflow.workflow INFO executing verb filter
10:32:12,261 datashaper.workflow.workflow INFO executing verb text_split
10:32:12,271 datashaper.workflow.workflow INFO executing verb drop
10:32:12,280 datashaper.workflow.workflow INFO executing verb merge
10:32:12,301 datashaper.workflow.workflow INFO executing verb text_embed
10:32:12,301 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=None
10:32:12,326 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
10:32:12,326 graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25
10:32:12,330 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 55 inputs via 55 snippets using 4 batches. max_batch_size=16, max_tokens=8191
10:32:12,965 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:32:12,967 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:32:12,968 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:32:12,969 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
10:32:13,493 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.157999999999447. input_tokens=280, output_tokens=0
10:32:13,726 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.393000000000029. input_tokens=504, output_tokens=0
10:32:13,767 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4340000000001965. input_tokens=696, output_tokens=0
10:32:13,784 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.451999999999316. input_tokens=712, output_tokens=0
10:32:13,821 datashaper.workflow.workflow INFO executing verb drop
10:32:13,832 datashaper.workflow.workflow INFO executing verb filter
10:32:13,847 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
10:32:14,21 graphrag.index.run INFO Running workflow: create_final_nodes...
10:32:14,21 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
10:32:14,22 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:32:14,42 datashaper.workflow.workflow INFO executing verb layout_graph
10:32:14,63 datashaper.workflow.workflow INFO executing verb unpack_graph
10:32:14,77 datashaper.workflow.workflow INFO executing verb unpack_graph
10:32:14,91 datashaper.workflow.workflow INFO executing verb drop
10:32:14,102 datashaper.workflow.workflow INFO executing verb filter
10:32:14,126 datashaper.workflow.workflow INFO executing verb select
10:32:14,137 datashaper.workflow.workflow INFO executing verb rename
10:32:14,148 datashaper.workflow.workflow INFO executing verb join
10:32:14,165 datashaper.workflow.workflow INFO executing verb convert
10:32:14,201 datashaper.workflow.workflow INFO executing verb rename
10:32:14,202 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
10:32:14,363 graphrag.index.run INFO Running workflow: create_final_communities...
10:32:14,363 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
10:32:14,363 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:32:14,388 datashaper.workflow.workflow INFO executing verb unpack_graph
10:32:14,404 datashaper.workflow.workflow INFO executing verb unpack_graph
10:32:14,421 datashaper.workflow.workflow INFO executing verb aggregate_override
10:32:14,435 datashaper.workflow.workflow INFO executing verb join
10:32:14,454 datashaper.workflow.workflow INFO executing verb join
10:32:14,472 datashaper.workflow.workflow INFO executing verb concat
10:32:14,486 datashaper.workflow.workflow INFO executing verb filter
10:32:14,524 datashaper.workflow.workflow INFO executing verb aggregate_override
10:32:14,552 datashaper.workflow.workflow INFO executing verb join
10:32:14,578 datashaper.workflow.workflow INFO executing verb filter
10:32:14,609 datashaper.workflow.workflow INFO executing verb fill
10:32:14,623 datashaper.workflow.workflow INFO executing verb merge
10:32:14,638 datashaper.workflow.workflow INFO executing verb copy
10:32:14,653 datashaper.workflow.workflow INFO executing verb select
10:32:14,655 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
10:32:14,782 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
10:32:14,782 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
10:32:14,782 graphrag.index.run INFO read table from storage: create_final_entities.parquet
10:32:14,817 datashaper.workflow.workflow INFO executing verb select
10:32:14,834 datashaper.workflow.workflow INFO executing verb unroll
10:32:14,851 datashaper.workflow.workflow INFO executing verb aggregate_override
10:32:14,854 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
10:32:14,985 graphrag.index.run INFO Running workflow: create_final_relationships...
10:32:14,986 graphrag.index.run INFO dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes']
10:32:14,986 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:32:14,989 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
10:32:15,23 datashaper.workflow.workflow INFO executing verb unpack_graph
10:32:15,42 datashaper.workflow.workflow INFO executing verb filter
10:32:15,79 datashaper.workflow.workflow INFO executing verb rename
10:32:15,95 datashaper.workflow.workflow INFO executing verb filter
10:32:15,132 datashaper.workflow.workflow INFO executing verb drop
10:32:15,149 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
10:32:15,169 datashaper.workflow.workflow INFO executing verb convert
10:32:15,204 datashaper.workflow.workflow INFO executing verb convert
10:32:15,206 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
10:32:15,344 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
10:32:15,344 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
10:32:15,355 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
10:32:15,399 datashaper.workflow.workflow INFO executing verb select
10:32:15,417 datashaper.workflow.workflow INFO executing verb unroll
10:32:15,438 datashaper.workflow.workflow INFO executing verb aggregate_override
10:32:15,458 datashaper.workflow.workflow INFO executing verb select
10:32:15,459 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
10:32:15,597 graphrag.index.run INFO Running workflow: create_final_community_reports...
10:32:15,597 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes']
10:32:15,597 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
10:32:15,601 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
10:32:15,640 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
10:32:15,661 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
10:32:15,682 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
10:32:15,707 datashaper.workflow.workflow INFO executing verb prepare_community_reports
10:32:15,708 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 55
10:32:15,751 datashaper.workflow.workflow INFO executing verb create_community_reports
10:32:22,173 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:22,179 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.416000000000167. input_tokens=4367, output_tokens=773
10:32:25,662 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
10:32:25,663 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.905999999999949. input_tokens=4185, output_tokens=861
10:32:25,706 datashaper.workflow.workflow INFO executing verb window
10:32:25,708 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
10:32:25,855 graphrag.index.run INFO Running workflow: create_final_text_units...
10:32:25,855 graphrag.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'create_base_text_units', 'join_text_units_to_relationship_ids']
10:32:25,855 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
10:32:25,858 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
10:32:25,860 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
10:32:25,902 datashaper.workflow.workflow INFO executing verb select
10:32:25,923 datashaper.workflow.workflow INFO executing verb rename
10:32:25,946 datashaper.workflow.workflow INFO executing verb join
10:32:25,973 datashaper.workflow.workflow INFO executing verb join
10:32:26,0 datashaper.workflow.workflow INFO executing verb aggregate_override
10:32:26,26 datashaper.workflow.workflow INFO executing verb select
10:32:26,28 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
10:32:26,179 graphrag.index.run INFO Running workflow: create_base_documents...
10:32:26,179 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
10:32:26,179 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
10:32:26,225 datashaper.workflow.workflow INFO executing verb unroll
10:32:26,250 datashaper.workflow.workflow INFO executing verb select
10:32:26,275 datashaper.workflow.workflow INFO executing verb rename
10:32:26,299 datashaper.workflow.workflow INFO executing verb join
10:32:26,326 datashaper.workflow.workflow INFO executing verb aggregate_override
10:32:26,351 datashaper.workflow.workflow INFO executing verb join
10:32:26,379 datashaper.workflow.workflow INFO executing verb rename
10:32:26,404 datashaper.workflow.workflow INFO executing verb convert
10:32:26,431 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
10:32:26,579 graphrag.index.run INFO Running workflow: create_final_documents...
10:32:26,579 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
10:32:26,580 graphrag.index.run INFO read table from storage: create_base_documents.parquet
10:32:26,657 datashaper.workflow.workflow INFO executing verb rename
10:32:26,658 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
